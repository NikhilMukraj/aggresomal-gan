{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '\\\\augmented_data\\\\'\n",
    "trainX = np.zeros((72_800, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_per = 10000\n",
    "curve = lambda x: np.sqrt(x)\n",
    "\n",
    "for n, i in enumerate(os.listdir(path)):\n",
    "    filename = os.fsdecode(i)\n",
    "    temp_img = cv2.imread(path + filename, 0)\n",
    "    temp_img = cv2.resize(temp_img, (128, 128))\n",
    "    trainX[n] = curve(np.asarray(temp_img))\n",
    "    if n % update_per == 0:\n",
    "        print(f'Image #: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator\n",
    "\n",
    "random_input = tf.keras.layers.Input(shape = 100)\n",
    "\n",
    "x = tf.keras.layers.Dense(img_size[0] * 5 * 5)(random_input)\n",
    "x = tf.keras.layers.Activation('swish')(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Reshape((5, 5, img_size[0]))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(5,5))(x)\n",
    "x = tf.keras.layers.Activation('swish')(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(7,7))(x)\n",
    "x = tf.keras.layers.Activation('swish')(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(16,16))(x)\n",
    "x = tf.keras.layers.Activation('swish')(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=(35,35))(x)\n",
    "generated_image = tf.keras.layers.Activation('sigmoid')(x)\n",
    "\n",
    "generator_network = tf.keras.models.Model(inputs=random_input, outputs=generated_image)\n",
    "generator_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old model\n",
    "\n",
    "discriminator_network = tf.keras.models.load_model(os.getcwd() + '\\\\dc_discriminator')\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.5)\n",
    "discriminator_network.compile(loss='binary_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n",
    "\n",
    "discriminator_network.trainable = False\n",
    "\n",
    "g_output = generator_network(random_input)\n",
    "d_output = discriminator_network(g_output)\n",
    "\n",
    "dcgan_model = tf.keras.models.Model(random_input, d_output)\n",
    "\n",
    "dcgan_model.compile(loss='binary_crossentropy', optimizer=adam_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [i for i in range(len(trainX))]\n",
    "\n",
    "def get_random_noise(batch_size, noise_size):\n",
    "    random_values = np.random.randn(batch_size*noise_size)\n",
    "    random_noise_batch = np.reshape(random_values, (batch_size, noise_size))\n",
    "    return random_noise_batch\n",
    "\n",
    "def get_fake_samples(generator_network, batch_size, noise_size):\n",
    "    random_noise_batch = get_random_noise(batch_size, noise_size) \n",
    "    fake_samples = generator_network.predict_on_batch(random_noise_batch)\n",
    "    return fake_samples\n",
    "\n",
    "def get_real_samples(batch_size):\n",
    "    random_indices = np.random.choice(indices, size=batch_size)\n",
    "    real_images = trainX[np.array(random_indices),:]\n",
    "    return real_images\n",
    "\n",
    "def show_generator_results(generator_network):\n",
    "    for k in range(9):\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        fake_samples = get_fake_samples(generator_network, 9, noise_size)\n",
    "        for j in range(9):\n",
    "            plt.subplot(990 + 1 + j)\n",
    "            plt.imshow(fake_samples[j,:,:,-1], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 100\n",
    "steps = 500\n",
    "noise_size = 100\n",
    "show_sample = True\n",
    "\n",
    "for i in range(0, epochs):\n",
    "    if show_sample and i % 10 == 0:\n",
    "        fake_samples = get_fake_samples(generator_network, 1, noise_size).reshape(img_size)\n",
    "        plt.title(f'Epoch: {i}')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(fake_samples, cmap='gray')\n",
    "        plt.show()\n",
    "    for j in range(steps):\n",
    "        fake_samples = get_fake_samples(generator_network, batch_size//2, noise_size).reshape((50,img_size[0],img_size[1]))\n",
    "        real_samples = get_real_samples(batch_size=batch_size//2)\n",
    "\n",
    "        fake_y = np.zeros((batch_size//2, 1))\n",
    "        real_y = np.ones((batch_size//2, 1))\n",
    "        \n",
    "        input_batch = np.vstack((fake_samples, real_samples))\n",
    "        output_labels = np.vstack((fake_y, real_y))\n",
    "        \n",
    "        discriminator_network.trainable=True\n",
    "        loss_d = discriminator_network.train_on_batch(input_batch, output_labels)\n",
    "        \n",
    "        gan_input = get_random_noise(batch_size, noise_size)\n",
    "        \n",
    "        gan_output = np.ones((batch_size))\n",
    "        \n",
    "        discriminator_network.trainable=False\n",
    "        loss_g = dcgan_model.train_on_batch(gan_input, gan_output)\n",
    "        \n",
    "        if j % 50 == 0:\n",
    "            print(f'Epoch: {i}, Step: {j}, D-Loss: {loss_d[0]:.3f}, D-Acc: {loss_d[1] * 100:.3f}, G-Loss: {loss_g:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_samples = get_fake_samples(generator_network, 1, noise_size).reshape(img_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(fake_samples, cmap='gray')\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b61de75f04c50e6f7e1cbb0ed0242dc28d93a4c85f12453d687141e6f56938f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
